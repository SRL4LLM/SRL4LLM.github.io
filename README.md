# Structured Representation Learning for LLMs (AAAI-26 Tutorial)

This is the website for the AAAI 2026 tutorial **“Structured Representation Learning: Interpretability, Robustness and Transferability for Large Language Models.”**

## Tutorial Information

- **Title**: Structured Representation Learning: Interpretability, Robustness and Transferability for Large Language Models  
- **Conference**: AAAI 2026 (Half-day tutorial: 3 hours + 30-min break)  
- **Presenters**:  
  - [Hanqi Yan](https://hanqi-qi.github.io/) (King’s College London) — hanqi.yan@kcl.ac.uk  
  - [Guangyi Chen](https://chengy12.github.io/) (Carnegie Mellon University; Mohamed bin Zayed University of AI) — guangyichen1994@gmail.com  
  - [Jonathan Richard Schwarz](https://jonathan-schwarz.github.io/) (Imperial College London; Thomson Reuters Foundational Research) — schwarzjn@gmail.com  

### Abstract

This tutorial presents principled methods for learning and using structured representations in LLMs to enable **interpretability**, **controllability**, and **transferability**, with practical guidance on efficient training, model editing, and robust generalization to new tasks and domains.

### Schedule:
- Session 1:	 Introduction
- Session 2: 	 The Principles of Representation Learning
- Session 3     Representations for Reasoning
- Coffee Break (30mins)
- Session 4: 	 Understand and Model Edit via Representation learning 
- Session 5:   Integrate Models Internals for Self-Improvements
- Session 6:   Conclusion and Future Work 


### Keywords

Large language models, representation learning, interpretability, efficiency, robustness, transferability
